# Jarvis Voice Agent (Modular Scaffold)

This package implements the modular architecture described in `Documentation/V1_ChatGPT_Handoff.md`.  
Each subsystem is isolated behind an interface so you can swap models or providers without touching the core orchestrator.

## Layout

```
jarvis/
├── config.py              # Centralised env/config loader
├── main.py                # FastAPI entry point and orchestrator bootstrap
├── audio/                 # Audio capture, buffering, and wake-word engines
├── transcription/         # Modular engines (Cheetah, Vosk, RealTimeSTT adapter)
├── llm/                   # Routing + provider clients (Ollama, Gemini)
├── tts/                   # Kokoro client
├── memory/                # Postgres/pgvector persistence
├── orchestrator/          # FSM + event contracts
├── telemetry/             # Logging/tracing wrappers
└── ui/                    # Floating ring UI bridge (WebSocket + static assets)
```

## Quick Start

```bash
cd "Voice system"
python -m venv .venv
source .venv/bin/activate
pip install -e .
uvicorn jarvis.main:app --reload
```

Environment variables are described in `jarvis/config.py`. Copy `.env.example` to `.env` and adjust for your machine.

### Voice Console Shortcuts

- Press `/` and hold to push-to-talk, release to stop listening.
- Click the ring to toggle manual wake.
- Use the model picker (top-left) to switch the orchestration LLM between Ollama and Gemini (if configured).
- The voice panel lets you preview (EN/HI) and save default Kokoro variants per persona.

The floating ring UI is served at `http://localhost:8010/ui`. It subscribes to the `/ws/state` WebSocket for transcription and orchestrator state updates.

### macOS (M3 Pro) tuning

- Keep `TRANSCRIPTION_ENGINE=cheetah` for the lowest latency captions. Provide `CHEETAH_ACCESS_KEY` and tweak `CHEETAH_ENDPOINT_SEC` (0.4 default) if you want faster flushes.
- For Hinglish-heavy speech, either set `TRANSCRIPTION_ENGINE=vosk` explicitly or rely on the runtime’s automatic language detection to hot-swap when Indic languages dominate.
- RealTimeSTT remains available (`TRANSCRIPTION_ENGINE=realtimestt`) but requires running its websocket server separately; keep it off unless you really need remote streaming.
- The resource monitor (`RESOURCE` events in the UI) surfaces CPU and memory use every ~30s so you can keep an eye on headroom while Kokoro/Ollama are active.
- Tap the floating ring to push-to-talk (amber glow while active). Tap again—or pause for ~1 s of silence—to auto-complete the turn. Saying “hey creo shutdown” will gracefully stop the service.

## Subsystems

- **Audio** — `jarvis.audio.*` captures mic input, manages the 12s ring buffer, and feeds both RealTimeSTT and wake-word engines. Replace `AudioCapture` if you have a different device stack.
- **Wake word** — drop-in engines live under `jarvis.audio.wakeword`. Porcupine (currently keyed to `jarvis` — switch back to `creo` once the new keyword model lands) and openWakeWord implement the same interface so you can hot-swap via env vars. When using Porcupine, set `PORCUPINE_ACCESS_KEY`, `PORCUPINE_KEYWORD_PATH`, and `PORCUPINE_MODEL_PATH` in `.env`.
- **Transcription** — Cheetah (default) and Vosk live under `jarvis/transcription`. Set `TRANSCRIPTION_ENGINE` in `.env` to bias the startup choice; the runtime still tries both and falls back automatically. RealTimeSTT lives at `https://github.com/rhasspy/realtimestt` if you want a remote backend.
- **LLM router** — `jarvis.llm.router.Router` decides between Ollama and Gemini. Each provider conforms to `ChatProvider`, so adding new models is straightforward.
- **TTS** — `jarvis.tts.kokoro.KokoroTTSClient` hits the Dockerised Kokoro endpoint. Voice presets from the handoff doc live in `jarvis/tts/voices.py`.
- **Memory** — `jarvis.memory.store.MemoryStore` wraps Postgres/pgvector. The current implementation seeds a minimal profile/ephemeral recall policy; extend it with embeddings + guardrails as you flesh out memory policies.
- **UI bridge** — `jarvis.ui.websocket.FloatingUIBridge` maintains WebSocket clients, serves the floating ring HTML, and surfaces periodic `MAINTENANCE` prompts generated by the self-maintenance scheduler.

## Telemetry & Logs

- Structured JSON logs via `structlog`; tweak fields in `jarvis/telemetry/logging.py`.
- OTLP tracing exporter is configured through `OTEL_EXPORTER_OTLP_ENDPOINT`. Remove it or leave blank to disable spans.
- Per-turn UI events include state transitions (`LISTENING`, `HOTWORD_HEARD`, `COMPOSING`, `SPEAKING`, `MAINTENANCE`) and ongoing transcripts so you can glue in other dashboards.

## Next Steps

1. Implement actual tool executors (web search, calendar) to replace the stub in `jarvis.main.ToolExecutorStub`.
2. Capture and store RLHF/feedback data surfaced during maintenance prompts.
3. Finalise wake-word capture sharing to avoid opening the microphone twice (currently Porcupine uses its own stream for reliability).
4. Expand `MemoryStore` with embedding pipelines and guard policies before persisting long-term facts.
5. Wire in real audio playback for Kokoro responses (e.g., using `sounddevice` or a websocket feed to the UI).

See `Documentation/Jarvis_Tools_and_Protocols.md` for a running list of tools, protocols, and maintenance routines.
For Postgres setup instructions, refer to `Documentation/Postgres_pgvector_Setup.md`.
